---
output:
  pdf_document:
    keep_tex: true
    citation_package: natbib
    number_sections: yes
fontsize: 11pt
# geometry: "left=1in,right=1in,top=1in,bottom=1in"
urlcolor: blue
header-includes:
- \usepackage{setspace}
- \usepackage{float}
- \usepackage{mathtools}
- \usepackage{natbib}
- \usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
- \setcitestyle{numbers,square,comma}
- \usepackage{verbatim}
- \usepackage{amsthm}
- \usepackage{comment}
bibliography: bibliography.bib
abstract: |
  asdf
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      # eval = FALSE,
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 3, 
                      fig.width = 5, 
                      fig.dpi = 300)

options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')

import::from(magrittr, `%>%`, `%<>%`)
library(ggplot2)
source('~/dev/pabm-grdpg/functions.R')
source('~/dev/manifold-block-models/functions.R')
```

```{=tex}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\tr}{\mathrm{Tr}}
\newcommand{\blockdiag}{\mathrm{blockdiag}}
\newcommand{\indep}{\stackrel{\mathrm{ind}}{\sim}}
\newcommand{\iid}{\stackrel{\mathrm{iid}}{\sim}}
\newcommand{\Bernoulli}{\mathrm{Bernoulli}}
\newcommand{\Betadist}{\mathrm{Beta}}
\newcommand{\BG}{\mathrm{BernoulliGraph}}
\newcommand{\Uniform}{\mathrm{Uniform}}
\newcommand{\PABM}{\mathrm{PABM}}
\newcommand{\RDPG}{\mathrm{RDPG}}
\newcommand{\GRDPG}{\mathrm{GRDPG}}
\newcommand{\Multinomial}{\mathrm{Multinomial}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\as}{\stackrel{\mathrm{a.s.}}{\to}}
\newcommand{\ER}{\text{Erd\"{o}s-R\'{e}nyi}}
\newcommand{\SBM}{\mathrm{SBM}}
\newcommand{\DCBM}{\mathrm{DCBM}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\MBM}{\mathrm{MBM}}
```

# Introduction

# Methods

# Simulation Study

## Classification

In this simulation experiment, the latent vectors were sampled along a Bezier curve defined by $g(t) = \begin{bmatrix} t^2 & 2 t (1-t) \end{bmatrix}^\top$. 
The timepoints $t_i$ were sampled as iid Beta random variables with two sets of parameters, $(\alpha_1, \beta_1)$ and $(\alpha_2, \beta_2)$. 
The setup is as follows:

1. Draw response variables $y_1, ..., y_n \iid \Multinomial(1/2, 1/2)$.
2. For each $i = 1, ..., n$, draw $t_i \mid y_i \indep \Betadist(\alpha_{y_i}, \beta_{y_i})$, such that
    * $\alpha_1 = 1$
    * $\beta_1 = 2$
    * $\alpha_2 = 2$
    * $\beta_2 = 1$
3. Construct each latent vector as $x_i = g(t_i)$ and compile them in data matrix $X = \begin{bmatrix} x_1 & \cdots & x_n \end{bmatrix}^\top$.
4. Sample graph and its adjacency matrix as $A \sim \RDPG(X)$. 

For each graph, we constructed the ASE, which was used to estimate the parameters $(\hat{\alpha}, \hat{\beta})$ for the graph, using the maximum likelihood method. 
The estimated parameters were then used as predictors $y_1, ..., y_n$, setting aside half for training and half for testing. 
We investigated graphs of size $|V| = 32, 64, 128, 256$. 
The number of graphs for each experiment was set to $n = 64$.
For each (number of graphs, size of graph) pair, we performed 32 replicates. 
Figure \ref{fig:class-sim-ase} shows the ASE of one graph.  
Figure \ref{fig:classification-sim} shows the boxplots of the classification error rates.

```{r class-sim-ase, cache = TRUE}
K <- 2
a.vec <- c(1, 2)
b.vec <- c(2, 1)
n <- 256

z <- 1

t. <- rbeta(n, a.vec[z], b.vec[z])
x1 <- t. ^ 2
x2 <- 2 * t. * (1 - t.)
X <- cbind(x1, x2)
P <- X %*% t(X)
A <- draw.graph(P)
Xhat <- embedding(A, 2, 0)

curve.est <- estimate.bezier.curve.2(Xhat, 
                                     degree = 2, 
                                     intercept = FALSE, 
                                     initialization = 'isomap', 
                                     min.t = 0, max.t = 1)
ggplot() + 
  geom_point(aes(x = Xhat[, 1], y = Xhat[, 2])) + 
  geom_point(aes(x = curve.est$X[, 1], y = curve.est$X[, 2]), 
             colour = 'red',
             size = .2) + 
  coord_fixed() + 
  labs(x = expression(x[1]), y = expression(x[2]))
```

```{r classification-sim}
sim.df <- readr::read_csv('~/Documents/postdoc-first-project/classification-sim.csv')

n.vec <- unique(sim.df$n)

sim.df %>% 
  ggplot() + 
  geom_boxplot(aes(x = n, y = 1 - acc, group = n)) + 
  scale_x_log10(breaks = sort(n.vec)) +
  # scale_y_log10() +
  theme_bw() + 
  labs(x = 'number of vertices', y = 'error rate')
```

## Regression

# Applications

HCP data

```{r hcp-eda, cache = TRUE}
data.dir <- '~/Downloads/repeated_10_scale_125/'
graph.list <- lapply(dir(data.dir), function(x) {
  graph <- igraph::read.graph(file.path(data.dir, x), format = 'graphml')
  A <- graph %>% 
    igraph::as_adjacency_matrix() %>% 
    as.matrix()
  z <- graph %>% 
    igraph::get.vertex.attribute() %>% 
    {.$dn_hemisphere} %>% 
    as.factor()
  return(list(A = A, z = z, id = substr(x, 1, 6)))
})

i <- 1
graph <- graph.list[[i]]
A <- graph$A
z <- graph$z
Xhat <- embedding(A, 2, 0, scale = TRUE)
clustering <- manifold.clustering(Xhat, 
                                  degree = 1,
                                  initialization = as.numeric(z),
                                  intercept = FALSE)
plot.estimated.curves(Xhat, clustering)
```

```{r hcp-gender, cache = TRUE}
hcp.df <- readr::read_csv('~/Documents/postdoc-first-project/hcp-eda.csv')
hcp.df %>% 
  na.omit() %>% 
  GGally::ggpairs(columns = 1:4, aes(colour = gender))
```
```{r hcp-age, cache = TRUE}
hcp.df <- readr::read_csv('~/Documents/postdoc-first-project/hcp-eda.csv')
hcp.df %>% 
  na.omit() %>% 
  dplyr::filter(age != '36+') %>% 
  GGally::ggpairs(columns = 1:4, aes(colour = age))
```

# Discussion

# Bibliography