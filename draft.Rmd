---
output:
  pdf_document:
    keep_tex: true
    citation_package: natbib
    number_sections: yes
fontsize: 11pt
# geometry: "left=1in,right=1in,top=1in,bottom=1in"
urlcolor: blue
header-includes:
- \usepackage{setspace}
- \usepackage{float}
- \usepackage{mathtools}
- \usepackage{natbib}
- \usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
- \setcitestyle{numbers,square,comma}
- \usepackage{verbatim}
- \usepackage{amsthm}
- \usepackage{comment}
bibliography: bibliography.bib
abstract: |
  asdf
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      # eval = FALSE,
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 3, 
                      fig.width = 5, 
                      fig.dpi = 300)

options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')

import::from(magrittr, `%>%`, `%<>%`)
library(ggplot2)
source('~/dev/pabm-grdpg/functions.R')
source('~/dev/manifold-block-models/functions.R')
```

```{=tex}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\tr}{\mathrm{Tr}}
\newcommand{\blockdiag}{\mathrm{blockdiag}}
\newcommand{\indep}{\stackrel{\mathrm{ind}}{\sim}}
\newcommand{\iid}{\stackrel{\mathrm{iid}}{\sim}}
\newcommand{\Bernoulli}{\mathrm{Bernoulli}}
\newcommand{\Betadist}{\mathrm{Beta}}
\newcommand{\BG}{\mathrm{BernoulliGraph}}
\newcommand{\Uniform}{\mathrm{Uniform}}
\newcommand{\PABM}{\mathrm{PABM}}
\newcommand{\RDPG}{\mathrm{RDPG}}
\newcommand{\GRDPG}{\mathrm{GRDPG}}
\newcommand{\Multinomial}{\mathrm{Multinomial}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\as}{\stackrel{\mathrm{a.s.}}{\to}}
\newcommand{\ER}{\text{Erd\"{o}s-R\'{e}nyi}}
\newcommand{\SBM}{\mathrm{SBM}}
\newcommand{\DCBM}{\mathrm{DCBM}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\MBM}{\mathrm{MBM}}
\newcommand{\Poisson}{\mathrm{Poisson}}
```

# Introduction

# Methods

# Simulation Study

## Classification

In this simulation experiment, the latent vectors were sampled along a Bezier curve defined by $g(t) = \begin{bmatrix} t^2 & 2 t (1-t) \end{bmatrix}^\top$. 
The timepoints $t_i$ were sampled as iid Beta random variables with two sets of parameters, $(\alpha_1, \beta_1)$ and $(\alpha_2, \beta_2)$. 
The setup is as follows:

1. Draw response variables $y_1, ..., y_n \iid \Multinomial(1/2, 1/2)$.
2. For each $i = 1, ..., n$, draw $t_i \mid y_i \indep \Betadist(\alpha_{y_i}, \beta_{y_i})$, such that
    * $\alpha_1 = 1$
    * $\beta_1 = 2$
    * $\alpha_2 = 2$
    * $\beta_2 = 1$
3. Construct each latent vector as $x_i = g(t_i)$ and compile them in data matrix $X = \begin{bmatrix} x_1 & \cdots & x_n \end{bmatrix}^\top$.
4. Sample graph and its adjacency matrix as $A \sim \RDPG(X)$. 

For each graph, we constructed the ASE, which was used to estimate the parameters $(\hat{\alpha}, \hat{\beta})$ for the graph, using the maximum likelihood method. 
The estimated parameters were then used as predictors $y_1, ..., y_n$, setting aside half for training and half for testing. 
We investigated graphs of size $|V| = 32, 64, 128, 256$. 
The number of graphs for each experiment was set to $n = 64$.
For each (number of graphs, size of graph) pair, we performed 32 replicates. 
Figure \ref{fig:class-sim-ase} shows the ASE of one graph.  
Figure \ref{fig:classification-sim} shows the boxplots of the classification error rates.

```{r class-sim-ase, cache = TRUE}
K <- 2
a.vec <- c(1, 2)
b.vec <- c(2, 1)
n <- 256

z <- 1

t. <- rbeta(n, a.vec[z], b.vec[z])
x1 <- t. ^ 2
x2 <- 2 * t. * (1 - t.)
X <- cbind(x1, x2)
P <- X %*% t(X)
A <- draw.graph(P)
Xhat <- embedding(A, 2, 0)

curve.est <- estimate.bezier.curve.2(Xhat, 
                                     degree = 2, 
                                     intercept = FALSE, 
                                     initialization = 'isomap', 
                                     min.t = 0, max.t = 1)
ggplot() + 
  geom_point(aes(x = Xhat[, 1], y = Xhat[, 2])) + 
  geom_point(aes(x = curve.est$X[, 1], y = curve.est$X[, 2]), 
             colour = 'red',
             size = .2) + 
  coord_fixed() + 
  labs(x = expression(x[1]), y = expression(x[2]))
```

```{r classification-sim}
sim.df <- readr::read_csv('~/Documents/postdoc-first-project/classification-sim.csv')

n.vec <- unique(sim.df$n)

sim.df %>% 
  ggplot() + 
  geom_boxplot(aes(x = n, y = 1 - acc, group = n)) + 
  scale_x_log10(breaks = sort(n.vec)) +
  # scale_y_log10() +
  theme_bw() + 
  labs(x = 'number of vertices', y = 'error rate')
```

## Regression

1. Draw angles $\theta_1, ..., \theta_N \iid \Uniform(\pi / 6, \pi / 3)$.
2. For each $k = 1, ..., N$, 
    i. Draw $t_1, ..., t_n \iid \Uniform(0, 1)$;
    ii. Draw $z_1, ..., z_n \iid \Multinomial(1/2, 1/2)$;
    iii. For each $i = 1, ..., n$, set $x_i = \begin{cases} \begin{bmatrix} t_i & 0 \end{bmatrix}^\top & z_i = 1 \\ \begin{bmatrix} t_i \cos \theta_k & t_i \sin \theta_k \end{bmatrix}^\top & z_i = 2 \end{cases}$;
    iv. Collect $X = \begin{bmatrix} x_1 & \cdots & x_n \end{bmatrix}^\top$ and draw $A \sim \RDPG(X)$;
    v. Set the response $y_k = \beta_0 + \beta_1 \theta_k$.

In this simulation, we set $\beta_0 = \beta_1 = 1$. 
The number of graphs was set to $N = 64$, and the number of vertices per graph was set to $n = 128, 256, 512, 1024$. 
For each $n$, we simulated 32 replicates. 

```{r angle-reg-example, cache = TRUE}
n <- 512
a.vec <- c(1, 1)
b.vec <- c(1, 1)
theta.min <- pi / 6
theta.max <- pi / 3
beta1 <- 1
beta0 <- 1

z <- sample(seq(2), n, replace = TRUE)
t. <- rbeta(n, a.vec[z], b.vec[z])
theta <- runif(1, theta.min, theta.max)
y <- beta0 + beta1 * theta
x1 <- ifelse(z == 1, t., cos(theta) * t.)
x2 <- ifelse(z == 1, 0, sin(theta) * t.)
X <- cbind(x1, x2)
P <- X %*% t(X)
A <- draw.graph(P)
Xhat <- embedding(A, 2, 0)
clustering <- manifold.clustering(Xhat, 
                                  degree = 1,
                                  initialization = z,
                                  intercept = FALSE)
plot.estimated.curves(Xhat, clustering) + 
  scale_colour_brewer(palette = 'Set1')
```

```{r angle-reg-results, cache = TRUE}
out.df <- readr::read_csv('~/dev/multilayer-rdpg/simulations/angle-regression-sim.csv')
n.vec <- c(128, 256, 512, 1024)
N <- 64

ggplot(out.df) + 
  geom_boxplot(aes(x = n, y = mse * N, group = n)) + 
  scale_x_log10(breaks = sort(n.vec)) +
  scale_y_log10() +
  labs(x = 'number of vertices', y = 'SSE') + 
  theme_bw()
```

# Applications

```{r load-hcp}
load('~/Downloads/HCP/HCP-Y/DTI_fMRI/Data.RData')
ids <- dimnames(dti.countV2)[[3]]
```

In the first example, we analyzed fiber count data between brain regions from the Human Connectome Project (HCP). 
When analyzing these data as graphs, we denote the regions as vertices and the fiber counts between pairs of regions as weighted edges. 
A plausible statistical model for these data is to assume that the edge weights between pairs of vertices is Poisson distributed, i.e., the adjacency matrix is sampled as $A_{ij} \indep \Poisson(\Theta_{ij})$, where $\Theta \in \mathbb{R}_+^{n \times n}$ is a symmetric matrix of Poisson parameters. 

In this dataset, there are $N = 136$ graphs (corresponding to individual subjects), each with $n = 68$ vertices (corresponding to brain regions). 
Analyzing these graphs as RDPGs reveals that the DCBM is a good candidate for these data (fig \ref{fig:hcp-ase}). 

```{r hcp-ase, cache = TRUE, fig.cap = 'ASE of one graph from the HCP dataset. The lines are fitted via $K$-curves clustering using degree = 1. The outputted clusters correspond exactly to the left (red) and right (blue) hemispheres.', fig.width = 10, fig.height = 10}
id <- ids[1]
A <- dti.countV2[, , id] %>% 
  unique() %>% 
  t() %>% 
  unique()
z <- colnames(A) %>% 
  stringi::stri_sub(-1, -1) %>% 
  as.factor()

Xhat <- embedding(A, 2, 0, scale = TRUE)
clustering <- manifold.clustering(Xhat, 
                                  degree = 1,
                                  initialization = as.numeric(z),
                                  normalize = TRUE,
                                  intercept = FALSE,
                                  parallel = FALSE)
plot.estimated.curves(Xhat, clustering) + 
  scale_colour_brewer(palette = 'Set1') + 
  ggrepel::geom_label_repel(aes(x = Xhat[, 1],
                                y = Xhat[, 2],
                                label = colnames(A)))
```

For each graph, the 

```{r hcp-gender, cache = TRUE}
hcp.df <- readr::read_csv('~/Documents/postdoc-first-project/hcp-eda.csv')
hcp.df %>% 
  na.omit() %>% 
  GGally::ggpairs(columns = 2:8, aes(colour = gender)) + 
  scale_colour_brewer(palette = 'Set1')
```
```{r hcp-age, cache = TRUE}
hcp.df <- readr::read_csv('~/Documents/postdoc-first-project/hcp-eda.csv')
hcp.df %>% 
  na.omit() %>% 
  dplyr::filter(age != '36+') %>% 
  GGally::ggpairs(columns = 2:8, aes(colour = age)) + 
  scale_colour_brewer(palette = 'Set1')
```

# Discussion

# Bibliography